Lab 1: Verification of Fisher’s Lemma Using Simulated Data from Normal Distributions
Theory
    • Fisher’s Lemma: Fisher's lemma states that for a sample from a normal distribution, the sample mean and sample variance are independent random variables.
    • Sample Mean: The sample mean (Xˉ) is an unbiased estimator of the population mean (μ).
    • Sample Variance: The sample variance (S2) is an unbiased estimator of the population variance (σ2).
Lab 1: Verification of Fisher’s Lemma
    • Sample Mean:
      Xˉ=n1​i=1∑n​Xi​
    • Sample Variance:
      S2=n−11​i=1∑n​(Xi​−Xˉ)2
    • Fisher’s Lemma: For a normal distribution, the sample mean (Xˉ) and sample variance (S2) are independent.

Objective
Verify Fisher’s lemma by generating samples from a normal distribution and checking the correlation between the sample mean and sample variance.
Pseudocode
    1. Generate multiple samples from a normal distribution with known mean (μ) and variance (σ2).
    2. Compute the sample mean and sample variance for each sample.
    3. Check the correlation between the sample means and sample variances.
    4. Plot histograms of the sample means and variances, and a scatterplot of means vs. variances.
Code
R
Copy
# Parameters
mu <- 5
sigma <- 2
n <- 30
N_sim <- 1000

# Initialize vectors
sample_means <- numeric(N_sim)
sample_vars <- numeric(N_sim)

# Simulation
set.seed(123)
for (i in 1:N_sim) {
    data <- rnorm(n, mean = mu, sd = sigma)
    sample_means[i] <- mean(data)
    sample_vars[i] <- var(data)
}

# Check correlation
correlation <- cor(sample_means, sample_vars)
print(paste("Correlation between sample mean and sample variance:", correlation))

# Graphical Output
par(mfrow = c(2, 2))

# Histogram of sample means
hist(sample_means, breaks = 30, col = "lightblue", main = "Distribution of Sample Means", xlab = "Sample Means")
curve(dnorm(x, mean = mu, sd = sigma/sqrt(n)), add = TRUE, col = "red", lwd = 2)

# Histogram of sample variances
hist(sample_vars, breaks = 30, col = "lightgreen", main = "Distribution of Sample Variances", xlab = "Sample Variances")
curve(dchisq((x * (n-1)) / sigma^2, df = n-1) * (n-1)/sigma^2, add = TRUE, col = "blue", lwd = 2)

# Scatterplot of sample means vs. sample variances
plot(sample_means, sample_vars, pch = 19, col = rgb(0, 0, 1, 0.5), main = "Sample Mean vs. Sample Variance")
abline(h = sigma^2, col = "red", lwd = 2)

# Q-Q plot for sample means
qqnorm(sample_means, main = "Q-Q Plot for Sample Means", col = "blue")
qqline(sample_means, col = "red", lwd = 2)
Sample Input/Output
    • Input: μ=5, σ=2, n=30, Nsim​=1000
    • Output:
        ◦ Correlation between sample mean and sample variance: Close to 0 (indicating independence).
        ◦ Histograms and scatterplots showing the distribution of sample means and variances.

Lab 2: Generation and Analysis of χ²-Distributed Data
Theory
    • Chi-Squared Distribution: The chi-squared distribution with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables.
    • Mean of χ²: The mean of a chi-squared distribution with k degrees of freedom is k.
    • Variance of χ²: The variance is 2k.
Chi-Squared Distribution:
      X∼χ2(k)
      where k is the degrees of freedom.
    • Mean of χ²:
      E[X]=k
    • Variance of χ²:
      Var(X)=2k

Objective
Generate chi-squared distributed data and analyze its properties, including mean and variance.
Pseudocode
    1. Generate chi-squared distributed data with k degrees of freedom.
    2. Compute the mean and variance of the generated data.
    3. Plot histograms, density plots, and Q-Q plots to visualize the distribution.
Code
R
Copy
# Parameters
k <- 5
N_sim <- 1000

# Generate chi-squared data
set.seed(123)
chi2_data <- rchisq(N_sim, df = k)

# Compute mean and variance
mean_chi2 <- mean(chi2_data)
var_chi2 <- var(chi2_data)
print(paste("Mean:", mean_chi2))
print(paste("Variance:", var_chi2))

# Graphical Output
par(mfrow = c(1, 3))

# Histogram
hist(chi2_data, breaks = 30, col = "lightblue", probability = TRUE, main = "Chi-Squared Distribution")
curve(dchisq(x, df = k), add = TRUE, col = "red", lwd = 2)

# Density plot
plot(density(chi2_data), col = "blue", lwd = 2, main = "Density Plot", xlab = "Value")
curve(dchisq(x, df = k), add = TRUE, col = "red", lwd = 2)

# Q-Q plot
qqplot(qchisq(ppoints(N_sim), df = k), chi2_data, main = "Q-Q Plot for Chi-Squared Data", col = "blue")
abline(0, 1, col = "red", lwd = 2)
Sample Input/Output
    • Input: k=5, Nsim​=1000
    • Output:
        ◦ Mean: Close to 5.
        ◦ Variance: Close to 10.
        ◦ Histograms and Q-Q plots showing the chi-squared distribution.

Lab 3: Comparison of t-Distribution with Normal Distribution for Small Sample Sizes
Theory
    • t-Distribution: The t-distribution is used when the sample size is small, and the population standard deviation is unknown. It has heavier tails than the normal distribution.
    • Normal Distribution: The normal distribution is symmetric and bell-shaped, with mean μ and variance σ2.
t-Distribution:
      T=S/n​Xˉ−μ​
      where T follows a t-distribution with n−1 degrees of freedom.
    • Normal Distribution:
      Z=σ/n​Xˉ−μ​
      where Z follows a standard normal distribution.


Objective
Compare the t-distribution with the normal distribution for small sample sizes.
Pseudocode
    1. Generate data from both t-distribution and normal distribution.
    2. Plot histograms and density plots to compare the two distributions.
    3. Generate Q-Q plots to assess normality.
Code
R
Copy
# Parameters
n <- 10
N_sim <- 1000

# Generate data
set.seed(123)
t_data <- rt(N_sim, df = n-1)
normal_data <- rnorm(N_sim)

# Graphical Output
par(mfrow = c(2, 2))

# Histogram of t-distribution
hist(t_data, breaks = 30, col = "lightblue", probability = TRUE, main = "t-Distribution", xlab = "Value")
curve(dt(x, df = n-1), add = TRUE, col = "red", lwd = 2)

# Histogram of normal distribution
hist(normal_data, breaks = 30, col = "lightgreen", probability = TRUE, main = "Normal Distribution", xlab = "Value")
curve(dnorm(x), add = TRUE, col = "blue", lwd = 2)

# Density plot comparison
plot(density(t_data), col = "red", lwd = 2, main = "Density Comparison", xlab = "Value", ylim = c(0, 0.4))
lines(density(normal_data), col = "blue", lwd = 2)
legend("topright", legend = c("t-Distribution", "Normal Distribution"), col = c("red", "blue"), lwd = 2)

# Q-Q plot for t-distribution
qqplot(qt(ppoints(N_sim), df = n-1), t_data, main = "Q-Q Plot for t-Distribution", col = "red", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "blue", lwd = 2)
Sample Input/Output
    • Input: n=10, Nsim​=1000
    • Output:
        ◦ Histograms and density plots showing the heavier tails of the t-distribution compared to the normal distribution.
        ◦ Q-Q plots indicating deviations from normality for the t-distribution.

Lab 4: Simulation of F-Distributed Data and Its Relationship with χ²-Distributions
Theory
    • F-Distribution: The F-distribution arises as the ratio of two chi-squared distributions. It is used in ANOVA and regression analysis.
    • Relationship with χ²: If U1​ and U2​ are independent chi-squared random variables with df1​ and df2​ degrees of freedom, then F=U2​/df2​U1​/df1​​ follows an F-distribution.
F-Distribution:
      F=U2​/df2​U1​/df1​​
      where U1​∼χ2(df1​) and U2​∼χ2(df2​).

Objective
Simulate F-distributed data and study its relationship with chi-squared distributions.
Pseudocode
    1. Generate two independent chi-squared datasets.
    2. Compute the F-distributed data as the ratio of the two chi-squared datasets.
    3. Plot histograms, density plots, and Q-Q plots to visualize the F-distribution.
Code
R
Copy
# Parameters
df1 <- 5
df2 <- 10
N_sim <- 1000

# Generate F-distributed data
set.seed(123)
chi2_1 <- rchisq(N_sim, df = df1)
chi2_2 <- rchisq(N_sim, df = df2)
f_data <- (chi2_1 / df1) / (chi2_2 / df2)

# Graphical Output
par(mfrow = c(2, 2))

# Histogram
hist(f_data, breaks = 30, col = "lightblue", probability = TRUE, main = "F-Distribution", xlab = "Value")
curve(df(x, df1 = df1, df2 = df2), add = TRUE, col = "red", lwd = 2)

# Density plot
plot(density(f_data), col = "blue", lwd = 2, main = "Density Plot", xlab = "Value")
curve(df(x, df1 = df1, df2 = df2), add = TRUE, col = "red", lwd = 2)

# Q-Q plot
qqplot(qf(ppoints(N_sim), df1 = df1, df2 = df2), f_data, main = "Q-Q Plot for F-Distribution", col = "blue")
abline(0, 1, col = "red", lwd = 2)

# Boxplot
boxplot(f_data, col = "lightgreen", main = "Boxplot of F-Distributed Data", ylab = "Value")
Sample Input/Output
    • Input: df1=5, df2=10, Nsim​=1000
    • Output:
        ◦ Histograms and density plots showing the F-distribution.
        ◦ Q-Q plots indicating the fit of the F-distribution.


Lab 8: Compare Biased and Unbiased Estimators
Theory
    • Biased Estimator: An estimator is biased if its expected value differs from the true parameter value.
    • Unbiased Estimator: An estimator is unbiased if its expected value equals the true parameter value.
    • Sample Variance: The sample variance S2=n−11​∑(Xi​−Xˉ)2 is unbiased, while n1​∑(Xi​−Xˉ)2 is biased.
Unbiased Variance:
      S2=n−11​i=1∑n​(Xi​−Xˉ)2
    • Biased Variance:
      σ^2=n1​i=1∑n​(Xi​−Xˉ)2

Objective
Compare biased and unbiased estimators of variance using simulated data.
Pseudocode
    1. Generate samples from a normal distribution.
    2. Compute both biased and unbiased sample variances.
    3. Compare the distributions of biased and unbiased variances.
Code
R
Copy
# Parameters
mu <- 5
sigma <- 2
n <- 30
N_sim <- 1000

# Initialize vectors
sample_vars <- numeric(N_sim)
biased_vars <- numeric(N_sim)

# Simulation
set.seed(123)
for (i in 1:N_sim) {
    data <- rnorm(n, mean = mu, sd = sigma)
    sample_vars[i] <- var(data)  # Unbiased
    biased_vars[i] <- sum((data - mean(data))^2) / n  # Biased
}

# Graphical Output
par(mfrow = c(1, 2))

# Histogram of unbiased variances
hist(sample_vars, breaks = 30, col = "lightblue", main = "Unbiased Sample Variance", xlab = "Variance")
abline(v = sigma^2, col = "red", lwd = 2)

# Histogram of biased variances
hist(biased_vars, breaks = 30, col = "lightgreen", main = "Biased Sample Variance", xlab = "Variance")
abline(v = sigma^2, col = "red", lwd = 2)
Sample Input/Output
    • Input: μ=5, σ=2, n=30, Nsim​=1000
    • Output:
        ◦ Histograms showing the distributions of biased and unbiased variances.
        ◦ The unbiased variance centers around σ2=4, while the biased variance is lower.


Lab 10: Derive MLEs for Binomial, Poisson, and Normal Distributions
Theory
    • Maximum Likelihood Estimation (MLE): A method to estimate the parameters of a statistical model by maximizing the likelihood function.
    • Binomial MLE: The MLE for p in a binomial distribution is p^​=number of trialsnumber of successes​.
    • Poisson MLE: The MLE for λ in a Poisson distribution is λ^=Xˉ.
    • Normal MLE: The MLE for μ is Xˉ, and for σ2 is n1​∑(Xi​−Xˉ)2.
Binomial MLE:
      p^​=number of trialsnumber of successes​
    • Poisson MLE:
      λ^=Xˉ
    • Normal MLE:
      μ^​=Xˉ,σ^2=n1​i=1∑n​(Xi​−Xˉ)2

Objective
Derive MLEs for the parameters of binomial, Poisson, and normal distributions using simulated data.
Pseudocode
    1. Generate data from binomial, Poisson, and normal distributions.
    2. Compute the MLEs for each distribution.
    3. Compare the MLEs to the true parameter values.
Code
R
Copy
# Binomial MLE
n_binom <- 20
p_true <- 0.6
data_binom <- rbinom(100, size = n_binom, prob = p_true)
p_mle <- mean(data_binom) / n_binom

# Poisson MLE
lambda_true <- 3
data_pois <- rpois(100, lambda = lambda_true)
lambda_mle <- mean(data_pois)

# Normal MLE
mu_true <- 5
sigma_true <- 2
data_norm <- rnorm(100, mean = mu_true, sd = sigma_true)
mu_mle <- mean(data_norm)
sigma_mle <- sqrt(mean((data_norm - mu_mle)^2))

# Output
print(paste("Binomial MLE for p:", p_mle))
print(paste("Poisson MLE for lambda:", lambda_mle))
print(paste("Normal MLE for mu:", mu_mle))
print(paste("Normal MLE for sigma:", sigma_mle))
Sample Input/Output
    • Input: Binomial (n=20, p=0.6), Poisson (λ=3), Normal (μ=5, σ=2)
    • Output:
        ◦ Binomial MLE for p: Close to 0.6.
        ◦ Poisson MLE for λ: Close to 3.
        ◦ Normal MLE for μ: Close to 5.
        ◦ Normal MLE for σ: Close to 2.

Lab 12: Derive the Best Critical Region for Simple vs. Composite Hypotheses
Theory
    • Critical Region: The set of values for which the null hypothesis is rejected.
    • Simple Hypothesis: A hypothesis that specifies the exact value of the parameter.
    • Composite Hypothesis: A hypothesis that specifies a range of values for the parameter.
Likelihood Ratio:
      Λ=L(θ1​)L(θ0​)​
    • Critical Region: Reject H0​ if Λ<k, where k is chosen based on α.

Objective
Derive the best critical region for testing simple vs. composite hypotheses.
Pseudocode
    1. Generate data under the null and alternative hypotheses.
    2. Compute the likelihood ratio for each dataset.
    3. Determine the critical region based on the likelihood ratio.
Code
R
Copy
# Parameters
mu0 <- 5  # Null hypothesis mean
mu1 <- 6  # Alternative hypothesis mean
sigma <- 2  # Population standard deviation
n <- 30  # Sample size
alpha <- 0.05  # Significance level

# Generate sample data under H0
set.seed(123)
sample_data_H0 <- rnorm(n, mean = mu0, sd = sigma)

# Generate sample data under H1
sample_data_H1 <- rnorm(n, mean = mu1, sd = sigma)

# Likelihood ratio test
likelihood_ratio <- function(data, mu0, mu1, sigma) {
    exp(sum(dnorm(data, mean = mu1, sd = sigma, log = TRUE)) -
    sum(dnorm(data, mean = mu0, sd = sigma, log = TRUE))
}

# Critical region
critical_value <- qnorm(1 - alpha, mean = mu0, sd = sigma / sqrt(n))

# Decision
decision_H0 <- mean(sample_data_H0) > critical_value
decision_H1 <- mean(sample_data_H1) > critical_value

# Output
print(paste("Critical Value:", critical_value))
print(paste("Decision under H0:", decision_H0))
print(paste("Decision under H1:", decision_H1))
Sample Input/Output
    • Input: μ0​=5, μ1​=6, σ=2, n=30, α=0.05
    • Output:
        ◦ Critical Value: The threshold for rejecting the null hypothesis.
        ◦ Decision under H0: Whether the null hypothesis is rejected.
        ◦ Decision under H1: Whether the alternative hypothesis is accepted.


Lab 14: Perform Hypothesis Testing Step-by-Step Using Real or Simulated Data
Theory
    • Hypothesis Testing Steps:
        1. State the null and alternative hypotheses.
        2. Choose a significance level (α).
        3. Calculate the test statistic.
        4. Determine the critical value or p-value.
        5. Make a decision (reject or fail to reject the null hypothesis).
Test Statistic:
      t=S/n​Xˉ−μ0​​
    • Critical Value:
      tα,n−1​


Objective
Perform hypothesis testing step-by-step using simulated data.
Pseudocode
    1. Generate sample data from a normal distribution.
    2. State the null and alternative hypotheses.
    3. Calculate the test statistic and p-value.
    4. Make a decision based on the p-value.
Code
R
Copy
# Parameters
mu0 <- 5  # Null hypothesis mean
mu1 <- 6  # True population mean
sigma <- 2  # Population standard deviation
n <- 30  # Sample size
alpha <- 0.05  # Significance level

# Generate sample data
set.seed(123)
sample_data <- rnorm(n, mean = mu1, sd = sigma)

# Step 1: State hypotheses
print("H0: mu = 5")
print("H1: mu > 5")

# Step 2: Choose significance level
print(paste("Significance level (alpha):", alpha))

# Step 3: Calculate test statistic
t_stat <- (mean(sample_data) - mu0) / (sd(sample_data) / sqrt(n))
print(paste("Test Statistic (t):", t_stat))

# Step 4: Determine critical value or p-value
critical_value <- qt(1 - alpha, df = n-1)
p_value <- pt(t_stat, df = n-1, lower.tail = FALSE)
print(paste("Critical Value:", critical_value))
print(paste("P-value:", p_value))

# Step 5: Make a decision
if (t_stat > critical_value) {
    decision <- "Reject H0"
} else {
    decision <- "Fail to reject H0"
}
print(paste("Decision:", decision))
Sample Input/Output
    • Input: μ0​=5, μ1​=6, σ=2, n=30, α=0.05
    • Output:
        ◦ Test Statistic: The calculated t-statistic.
        ◦ P-value: The probability of observing the test statistic under the null hypothesis.
        ◦ Decision: Whether to reject or fail to reject the null hypothesis.

Lab 15: Compare the Power of Different Tests for the Same Hypothesis
Theory
    • Power of a Test: The probability of correctly rejecting the null hypothesis when the alternative hypothesis is true.
    • t-Test vs. z-Test: The t-test is used for small samples, while the z-test is used for large samples.
Power of t-Test:
      Power=P(Reject H0​∣H1​ is true)
    • Power of z-Test:
      Power=P(Reject H0​∣H1​ is true)

Objective
Compare the power of the t-test and z-test for the same hypothesis.
Pseudocode
    1. Generate data under the alternative hypothesis.
    2. Perform both t-tests and z-tests.
    3. Calculate the power of each test.
Code
R
Copy
# Parameters
mu0 <- 5  # Null hypothesis mean
mu1 <- 6  # Alternative hypothesis mean
sigma <- 2  # Population standard deviation
n <- 30  # Sample size
alpha <- 0.05  # Significance level
N_sim <- 1000  # Number of simulations

# Initialize power counters
power_t_test <- 0
power_z_test <- 0

# Simulation
set.seed(123)
for (i in 1:N_sim) {
    # Simulate data under H1
    data <- rnorm(n, mean = mu1, sd = sigma)

    # Perform t-test
    t_test <- t.test(data, mu = mu0, alternative = "greater")
    if (t_test$p.value < alpha) {
        power_t_test <- power_t_test + 1
    }

    # Perform z-test
    z_stat <- (mean(data) - mu0) / (sigma / sqrt(n))
    z_critical <- qnorm(1 - alpha)
    if (z_stat > z_critical) {
        power_z_test <- power_z_test + 1
    }
}

# Output
print(paste("Power of t-test:", power_t_test / N_sim))
print(paste("Power of z-test:", power_z_test / N_sim))
Sample Input/Output
    • Input: μ0​=5, μ1​=6, σ=2, n=30, α=0.05, Nsim​=1000
    • Output:
        ◦ Power of t-test: The probability of correctly rejecting the null hypothesis using the t-test.
        ◦ Power of z-test: The probability of correctly rejecting the null hypothesis using the z-test.

Lab 16: Apply Bartlett’s Test to Compare Variances Across Multiple Groups
Theory
    • Bartlett’s Test: A statistical test used to compare the variances of multiple groups. It assumes that the data is normally distributed.
    • Null Hypothesis: All groups have equal variances.
Bartlett’s Test Statistic:
T=1+3(k−1)1​(∑i=1k​ni​−11​−N−k1​)(N−k)ln(Sp2​)−∑i=1k​(ni​−1)ln(Si2​)​
where Sp2​ is the pooled variance.


Objective
Apply Bartlett’s test to compare the variances of multiple groups.
Pseudocode
    1. Generate data for multiple groups with different variances.
    2. Perform Bartlett’s test to compare the variances.
    3. Interpret the results.
Code
R
Copy
# Generate sample data for three groups
set.seed(123)
group1 <- rnorm(30, mean = 5, sd = 2)
group2 <- rnorm(30, mean = 5, sd = 3)
group3 <- rnorm(30, mean = 5, sd = 4)

# Combine data into a list
data_list <- list(group1, group2, group3)

# Perform Bartlett’s test
bartlett_test_result <- bartlett.test(data_list)

# Output
print(bartlett_test_result)
Sample Input/Output
    • Input: Three groups with different variances.
    • Output:
        ◦ Bartlett’s test result: Whether to reject the null hypothesis of equal variances.

Lab 17: Perform Fisher’s Exact Test on 2×2 Contingency Tables
Theory
    • Fisher’s Exact Test: A statistical test used to determine if there are nonrandom associations between two categorical variables in a 2×2 contingency table.
    • Null Hypothesis: The two variables are independent.
Fisher’s Exact Test:
p=(a+cn​)(aa+b​)(cc+d​)​
where a,b,c,d are the cell counts in a 2×2 table.


Objective
Perform Fisher’s exact test on a 2×2 contingency table.
Pseudocode
    1. Create a 2×2 contingency table.
    2. Perform Fisher’s exact test.
    3. Interpret the results.
Code
R
Copy
# Create a 2x2 contingency table
data <- matrix(c(10, 5, 2, 8), nrow = 2, byrow = TRUE)
rownames(data) <- c("Group A", "Group B")
colnames(data) <- c("Success", "Failure")

# Perform Fisher’s exact test
fisher_test_result <- fisher.test(data)

# Output
print(data)
print(fisher_test_result)
Sample Input/Output
    • Input: A 2×2 contingency table.
    • Output:
        ◦ Fisher’s exact test result: Whether to reject the null hypothesis of independence.

Lab 19: Conduct Non-Parametric Tests
Theory
    • Non-Parametric Tests: Statistical tests that do not assume a specific distribution for the data.
    • Wilcoxon Rank-Sum Test: A non-parametric test to compare two independent samples.
Wilcoxon Rank-Sum Test:
      W=i=1∑n1​​Ri​
      where Ri​ are the ranks of the first sample.

Objective
Conduct a non-parametric test (Wilcoxon rank-sum test) to compare two groups.
Pseudocode
    1. Generate data for two groups.
    2. Perform the Wilcoxon rank-sum test.
    3. Interpret the results.
Code
R
Copy
# Generate sample data
set.seed(123)
group1 <- rnorm(20, mean = 5, sd = 2)
group2 <- rnorm(20, mean = 7, sd = 2)

# Perform Wilcoxon rank-sum test
wilcox_test_result <- wilcox.test(group1, group2)

# Output
print(wilcox_test_result)
Sample Input/Output
    • Input: Two groups with different means.
    • Output:
        ◦ Wilcoxon rank-sum test result: Whether to reject the null hypothesis of equal medians.


https://chat.deepseek.com/a/chat/s/d114bad3-d23a-49ac-aaa3-ba260fe03581
